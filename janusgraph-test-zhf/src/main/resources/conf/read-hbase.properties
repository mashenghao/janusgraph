# read-cassandra-3.properties
#
# Hadoop Graph Configuration
#
gremlin.graph=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph
gremlin.hadoop.graphReader=org.janusgraph.hadoop.formats.hbase.HBaseInputFormat
#gremlin.hadoop.graphWriter=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormat
gremlin.hadoop.graphWriter=org.apache.tinkerpop.gremlin.hadoop.structure.io.graphson.GraphSONOutputFormat
gremlin.hadoop.jarsInDistributedCache=true
gremlin.hadoop.inputLocation=persisted_rdd
gremlin.hadoop.outputLocation=persisted_rdd
gremlin.spark.persistContext=true
gremlin.spark.graphStorageLevel=DISK_ONLY
#
# JanusGraph Cassandra InputFormat configuration
#
# These properties defines the connection properties which were used while write data to JanusGraph.
janusgraphmr.ioformat.conf.storage.backend=hbase
# This specifies the hostname & port for Cassandra data store.
janusgraphmr.ioformat.conf.storage.hostname=10.100.2.110,10.100.2.120,10.100.2.130
#janusgraphmr.ioformat.conf.storage.hostname=10.1.100.1,10.1.100.2,10.1.100.3
janusgraphmr.ioformat.conf.storage.port=2181
# This specifies the keyspace where data is stored.
#janusgraphmr.ioformat.conf.storage.hbase.table=communitydt2000
janusgraphmr.ioformat.conf.storage.hbase.table=janusgraph.tmptest1
#janusgraphmr.ioformat.conf.storage.hbase.table=tmptest19
#janusgraphmr.ioformat.conf.storage.hbase.table=experiment_156
# This defines the indexing backned configuration used while writing data to JanusGraph.
#janusgraphmr.ioformat.conf.index.search.backend=elasticsearch
#janusgraphmr.ioformat.conf.index.search.hostname=10.100.1.16,10.100.1.21,10.100.1.22,10.100.1.23,10.100.1.24
# Use the appropriate properties for the backend when using a different storage backend (HBase) or indexing backend (Solr).

#
# Apache Cassandra InputFormat configuration
#
#cassandra.input.partitioner.class=org.apache.cassandra.dht.Murmur3Partitioner

#
# SparkGraphComputer Configuration
#
spark.master=local
spark.executor.memory=500m
spark.driver.memory=100m
spark.executor.instances=3
spark.executor.cores=1
spark.deploy-mode=cluster
#spark.yarn.queue=q2
#spark.default.parallelism=200
#spark.driver.memory=1g
spark.rdd.compress=true
spark.serializer=org.apache.tinkerpop.gremlin.spark.structure.io.gryo.GryoSerializer
spark.yarn.jars=D:\\git\\janusgraph-spark\\target\\janusgraph-spark-1.0.2.jar
#spark.yarn.am.extraJavaOptions=-Djava.library.path=/home/hadoop/hadoop/lib/native
#spark.yarn.appMasterEnv.JAVA_HOME=/home/hadoop/jdk1.8.0_151/jre
#spark.executorEnv.JAVA_HOME=/home/hadoop/jdk1.8.0_151/jre
#spark.executor.extraClassPath=D:\\git\\janusgraph-spark\\target\\janusgraph-spark-1.0.2.jar
#spark.kryo.registrator=org.apache.tinkerpop.gremlin.spark.structure.io.gryo.GryoRegistrator
#spark.kryo.registrationRequired=false
spark.executor.extraJavaOptions=-Dlog4j.configuration=/home/hadoop/janusgraph-0.3.0-hadoop2/conf/gremlin-server/log4j-server.properties
